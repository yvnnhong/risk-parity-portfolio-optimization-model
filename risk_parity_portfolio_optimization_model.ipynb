{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MzGoccABD6q2"
      },
      "outputs": [],
      "source": [
        "# My Project: Optimized Risk Parity Portfolio Backtester\n",
        "# Overview:\n",
        "# This Jupyter Colab notebook implements an advanced Risk Parity Portfolio\n",
        "# Optimization model with reinforcement learning and sophisticated backtesting.\n",
        "# The project allocates capital to assets such that each contributes equally to\n",
        "# the portfolio's total risk, using historical asset data and a covariance matrix.\n",
        "# Key features:\n",
        "# - User inputs for asset tickers, start date, and end date to fetch historical\n",
        "#   data from yfinance\n",
        "# - Robust risk parity optimization using CVXPY, accounting for covariance\n",
        "#   matrix uncertainty\n",
        "# - Reinforcement Learning (Q-learning) to dynamically adjust portfolio weights\n",
        "#   based on market conditions, maximizing risk-adjusted returns\n",
        "# - Sophisticated backtesting with transaction costs, slippage, rolling\n",
        "#   covariance estimation, and portfolio turnover tracking\n",
        "# - Comprehensive performance metrics: Sharpe ratio, Sortino ratio, annualized\n",
        "#   return, maximum drawdown, Calmar ratio, volatility, Omega ratio, and\n",
        "#   Conditional Value-at-Risk (CVaR).\n",
        "# - Visualizations for portfolio weights, performance, turnover, and CVaR over time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 2 START\n",
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import cvxpy as cp\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, date\n",
        "import os\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "etUicpfLHiW4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 3 START\n",
        "# Step 1: User Input and Data Collection\n",
        "def validate_date(date_str):\n",
        "    \"\"\"\n",
        "    Validate date format (YYYY-MM-DD) and ensure it's a valid date.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        datetime.strptime(date_str, '%Y-%m-%d')\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "def load_cached_data(cache_file, tickers, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Load cached data if available and valid.\n",
        "    \"\"\"\n",
        "    if os.path.exists(cache_file):\n",
        "        cached_data = pd.read_csv(cache_file, index_col=0, parse_dates=True)\n",
        "        cached_tickers = cached_data.columns.tolist()\n",
        "        cached_start = cached_data.index.min().strftime('%Y-%m-%d')\n",
        "        cached_end = cached_data.index.max().strftime('%Y-%m-%d')\n",
        "        if (set(tickers) == set(cached_tickers) and\n",
        "            cached_start <= start_date and\n",
        "            cached_end >= end_date):\n",
        "            print(\"Using cached data.\")\n",
        "            data = cached_data[tickers]\n",
        "            data = data.ffill().dropna()\n",
        "            returns = data.pct_change().dropna()\n",
        "            return data, returns\n",
        "    return None, None\n",
        "\n",
        "def fetch_data(tickers, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Fetch historical adjusted close prices for given tickers from Yahoo Finance.\n",
        "    \"\"\"\n",
        "    data = yf.download(tickers, start=start_date, end=end_date, auto_adjust=True, progress=False)['Close']\n",
        "    if data.empty or data.shape[0] == 0:\n",
        "        raise ValueError(\"No data retrieved from Yahoo Finance.\")\n",
        "    data = data.ffill().dropna()\n",
        "    returns = data.pct_change().dropna()\n",
        "    return data, returns\n",
        "\n",
        "# Cache file path\n",
        "cache_file = \"market_data_cache.csv\"\n",
        "\n",
        "# Get user input\n",
        "tickers = [t.strip() for t in input(\"Enter tickers (comma-separated, e.g., SPY,TLT,GLD): \").split(\",\") if t.strip()]\n",
        "start_date = input(\"Enter start date (YYYY-MM-DD, e.g., 2021-01-01): \")\n",
        "end_date = input(\"Enter end date (YYYY-MM-DD, e.g., 2025-01-01): \")\n",
        "\n",
        "# Validate inputs\n",
        "if not tickers:\n",
        "    print(\"No valid tickers provided. Please enter at least one ticker.\")\n",
        "    raise ValueError(\"No valid tickers provided.\")\n",
        "\n",
        "if not validate_date(start_date):\n",
        "    print(\"Invalid start date format. Use YYYY-MM-DD.\")\n",
        "    raise ValueError(\"Invalid start date format.\")\n",
        "\n",
        "if not validate_date(end_date) or datetime.strptime(end_date, '%Y-%m-%d') <= datetime.strptime(start_date, '%Y-%m-%d'):\n",
        "    print(\"Invalid end date. Use YYYY-MM-DD and ensure end date is after start date.\")\n",
        "    raise ValueError(\"Invalid end date.\")\n",
        "\n",
        "# Try loading cached data\n",
        "prices, returns = load_cached_data(cache_file, tickers, start_date, end_date)\n",
        "\n",
        "# Fetch data if no valid cache\n",
        "if prices is None or returns is None:\n",
        "    try:\n",
        "        prices, returns = fetch_data(tickers, start_date, end_date)\n",
        "        prices.to_csv(cache_file)\n",
        "        print(\"Data fetched successfully and cached!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data: {e}\")\n",
        "        print(\"Possible rate limit. Wait 5-10 minutes, try fewer tickers, or check your network.\")\n",
        "        raise SystemExit(\"Exiting due to data fetching failure.\")\n",
        "\n",
        "# Validate data\n",
        "if prices.empty or returns.empty:\n",
        "    print(\"No valid data retrieved. Exiting.\")\n",
        "    raise SystemExit(\"Exiting due to empty data.\")\n",
        "\n",
        "print(f\"Prices shape: {prices.shape}\")\n",
        "print(f\"Returns shape: {returns.shape}\")\n",
        "# CELL 3 END"
      ],
      "metadata": {
        "id": "wETOYpWIRLxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4 START\n",
        "# Step 2: Robust Risk Parity Optimization\n",
        "def risk_parity_weights(returns, max_iter=1000, robust=False, uncertainty_scale=0.1):\n",
        "    \"\"\"\n",
        "    Compute risk parity weights using CVXPY, with optional robust optimization.\n",
        "    \"\"\"\n",
        "    n_assets = returns.shape[1]\n",
        "    cov_matrix = returns.cov().values\n",
        "    w = cp.Variable(n_assets)\n",
        "    risk = cp.sqrt(w.T @ cov_matrix @ w)\n",
        "\n",
        "    risk_contributions = []\n",
        "    for i in range(n_assets):\n",
        "        rc = w[i] * (cov_matrix @ w)[i] / risk\n",
        "        risk_contributions.append(rc)\n",
        "\n",
        "    if robust:\n",
        "        cov_uncertainty = uncertainty_scale * np.std(cov_matrix) * np.eye(n_assets)\n",
        "        robust_risk = cp.sqrt(w.T @ (cov_matrix + cov_uncertainty) @ w)\n",
        "        objective = cp.Minimize(cp.sum_squares(cp.vstack(risk_contributions)) + robust_risk)\n",
        "    else:\n",
        "        objective = cp.Minimize(cp.sum_squares(cp.vstack(risk_contributions)))\n",
        "\n",
        "    constraints = [cp.sum(w) == 1, w >= 0]\n",
        "    problem = cp.Problem(objective, constraints)\n",
        "    problem.solve(max_iter=max_iter)\n",
        "\n",
        "    if problem.status != cp.OPTIMAL:\n",
        "        raise ValueError(\"Optimization did not converge\")\n",
        "\n",
        "    return w.value\n",
        "\n",
        "# Compute initial weights\n",
        "weights = risk_parity_weights(returns, robust=True, uncertainty_scale=0.1)\n",
        "weights_df = pd.Series(weights, index=tickers, name='Robust Risk Parity Weights')\n",
        "# CELL 4 END"
      ],
      "metadata": {
        "id": "8AomrZcGRPJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 5 START\n",
        "# Step 3: Reinforcement Learning for Dynamic Weight Adjustment\n",
        "class QLearningAgent:\n",
        "    def __init__(self, n_assets, n_states=10, learning_rate=0.1, discount_factor=0.95, epsilon=0.1):\n",
        "        \"\"\"\n",
        "        Q-learning agent to adjust portfolio weights based on market states.\n",
        "        \"\"\"\n",
        "        self.n_assets = n_assets\n",
        "        self.n_states = n_states\n",
        "        self.q_table = np.zeros((n_states, n_assets))\n",
        "        self.learning_rate = learning_rate\n",
        "        self.discount_factor = discount_factor\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def get_state(self, returns, lookback=20):\n",
        "        \"\"\"\n",
        "        Discretize market state based on recent returns and volatility.\n",
        "        \"\"\"\n",
        "        recent_returns = returns[-lookback:].mean()\n",
        "        volatility = returns[-lookback:].std()\n",
        "        return min(int((recent_returns / volatility) * self.n_states / 2 + self.n_states / 2), self.n_states - 1)\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        \"\"\"\n",
        "        Epsilon-greedy action selection.\n",
        "        \"\"\"\n",
        "        if np.random.rand() < self.epsilon:\n",
        "            return np.random.randint(self.n_assets)\n",
        "        return np.argmax(self.q_table[state])\n",
        "\n",
        "    def update(self, state, action, reward, next_state):\n",
        "        \"\"\"\n",
        "        Update Q-table based on reward and next state.\n",
        "        \"\"\"\n",
        "        best_next_action = np.argmax(self.q_table[next_state])\n",
        "        self.q_table[state, action] += self.learning_rate * (\n",
        "            reward + self.discount_factor * self.q_table[next_state, best_next_action] - self.q_table[state, action]\n",
        "        )\n",
        "\n",
        "    def adjust_weights(self, weights, action, step_size=0.1):\n",
        "        \"\"\"\n",
        "        Adjust portfolio weights based on selected action.\n",
        "        \"\"\"\n",
        "        new_weights = weights.copy()\n",
        "        new_weights[action] += step_size\n",
        "        if new_weights[action] > 1:\n",
        "            new_weights[action] = 1\n",
        "        elif new_weights[action] < 0:\n",
        "            new_weights[action] = 0\n",
        "        new_weights = new_weights / np.sum(new_weights)\n",
        "        return new_weights\n",
        "\n",
        "def train_rl_agent(returns, weights, lookback=20, n_episodes=50):\n",
        "    \"\"\"\n",
        "    Train Q-learning agent to optimize portfolio weights.\n",
        "    \"\"\"\n",
        "    agent = QLearningAgent(n_assets=len(tickers))\n",
        "    for episode in range(n_episodes):\n",
        "        for t in range(lookback, len(returns)):\n",
        "            state = agent.get_state(returns.iloc[:t])\n",
        "            action = agent.choose_action(state)\n",
        "            new_weights = agent.adjust_weights(weights, action)\n",
        "\n",
        "            next_returns = returns.iloc[t:t+lookback]\n",
        "            portfolio_returns = np.sum(next_returns * new_weights, axis=1)\n",
        "            reward = np.mean(portfolio_returns) / np.std(portfolio_returns) * np.sqrt(252) if np.std(portfolio_returns) > 0 else 0\n",
        "\n",
        "            next_state = agent.get_state(returns.iloc[:t+1])\n",
        "            agent.update(state, action, reward, next_state)\n",
        "\n",
        "    return agent\n",
        "\n",
        "# Train RL agent\n",
        "rl_agent = train_rl_agent(returns, weights)\n",
        "# CELL 5 END"
      ],
      "metadata": {
        "id": "qqW2xRXfMOon"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 6 START\n",
        "# Step 4: Sophisticated Backtesting Framework\n",
        "def backtest_portfolio(prices, returns, weights, rl_agent=None, rebalance_freq='M', lookback=20, cov_window=60, trans_cost=0.001, slippage=0.0005):\n",
        "    \"\"\"\n",
        "    Backtest portfolio with transaction costs, slippage, rolling covariance, and RL adjustments.\n",
        "    \"\"\"\n",
        "    portfolio_value = [10000]\n",
        "    holdings = (portfolio_value[0] * weights / prices[tickers].iloc[0]).values\n",
        "    weights_history = [weights]\n",
        "    turnover = []\n",
        "    n_assets = len(tickers)\n",
        "\n",
        "    for i in range(1, len(prices)):\n",
        "        # Calculate portfolio value\n",
        "        value = np.sum(holdings * prices[tickers].iloc[i])\n",
        "        portfolio_value.append(value)\n",
        "\n",
        "        # Rebalance monthly\n",
        "        if rebalance_freq == 'M' and prices.index[i].is_month_end and i >= cov_window:\n",
        "            # Rolling covariance for risk parity\n",
        "            cov_returns = returns.iloc[max(0, i-cov_window):i]\n",
        "            new_weights = risk_parity_weights(cov_returns, robust=True, uncertainty_scale=0.1)\n",
        "\n",
        "            # RL adjustment\n",
        "            if rl_agent:\n",
        "                state = rl_agent.get_state(returns.iloc[:i], lookback)\n",
        "                action = rl_agent.choose_action(state)\n",
        "                new_weights = rl_agent.adjust_weights(new_weights, action)\n",
        "\n",
        "            # Calculate turnover and costs\n",
        "            old_weights = holdings * prices[tickers].iloc[i] / value\n",
        "            turnover.append(np.sum(np.abs(new_weights - old_weights)))\n",
        "            cost = trans_cost * turnover[-1] * value + slippage * turnover[-1] * value\n",
        "            value -= cost\n",
        "\n",
        "            # Update holdings\n",
        "            holdings = (value * new_weights / prices[tickers].iloc[i]).values\n",
        "            weights_history.append(new_weights)\n",
        "\n",
        "    portfolio_series = pd.Series(portfolio_value, index=prices.index)\n",
        "    portfolio_returns = portfolio_series.pct_change().dropna()\n",
        "\n",
        "    # Performance metrics\n",
        "    annualized_return = np.mean(portfolio_returns) * 252\n",
        "    volatility = np.std(portfolio_returns) * np.sqrt(252)\n",
        "    sharpe_ratio = annualized_return / volatility if volatility > 0 else 0\n",
        "    downside_returns = portfolio_returns[portfolio_returns < 0]\n",
        "    sortino_ratio = annualized_return / (np.std(downside_returns) * np.sqrt(252)) if len(downside_returns) > 0 else 0\n",
        "    max_drawdown = np.min(portfolio_series / portfolio_series.cummax() - 1)\n",
        "    calmar_ratio = annualized_return / abs(max_drawdown) if max_drawdown != 0 else 0\n",
        "\n",
        "    # Omega ratio (threshold = 0)\n",
        "    threshold = 0\n",
        "    gains = portfolio_returns[portfolio_returns > threshold].sum()\n",
        "    losses = -portfolio_returns[portfolio_returns <= threshold].sum()\n",
        "    omega_ratio = gains / losses if losses > 0 else np.inf\n",
        "\n",
        "    # CVaR (5% worst returns)\n",
        "    cvar = np.mean(portfolio_returns[portfolio_returns <= np.percentile(portfolio_returns, 5)]) if len(portfolio_returns) > 0 else 0\n",
        "\n",
        "    return portfolio_series, weights_history, turnover, {\n",
        "        'Sharpe Ratio': sharpe_ratio,\n",
        "        'Sortino Ratio': sortino_ratio,\n",
        "        'Annualized Return': annualized_return,\n",
        "        'Max Drawdown': max_drawdown,\n",
        "        'Calmar Ratio': calmar_ratio,\n",
        "        'Volatility': volatility,\n",
        "        'Omega Ratio': omega_ratio,\n",
        "        'CVaR': cvar\n",
        "    }\n",
        "\n",
        "# Run backtest\n",
        "portfolio_value, weights_history, turnover, metrics = backtest_portfolio(prices, returns, weights, rl_agent=rl_agent)\n",
        "# CELL 6 END"
      ],
      "metadata": {
        "id": "BX9JR8wdMTIh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 7 START\n",
        "# Step 5: Visualization and Results\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Portfolio weights\n",
        "plt.subplot(2, 2, 1)\n",
        "weights_df = pd.DataFrame(weights_history, index=prices.index[:len(weights_history)], columns=tickers)\n",
        "weights_df.plot(ax=plt.gca(), title='Portfolio Weights Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Weight')\n",
        "\n",
        "# Portfolio value\n",
        "plt.subplot(2, 2, 2)\n",
        "portfolio_value.plot(title='Portfolio Value Over Time (RL-Adjusted)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Portfolio Value ($)')\n",
        "\n",
        "# Turnover\n",
        "plt.subplot(2, 2, 3)\n",
        "pd.Series(turnover, index=prices.index[1:len(turnover)+1]).plot(title='Portfolio Turnover')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Turnover')\n",
        "\n",
        "# CVaR\n",
        "plt.subplot(2, 2, 4)\n",
        "rolling_cvar = portfolio_value.pct_change().dropna().rolling(20).apply(lambda x: np.mean(x[x <= np.percentile(x, 5)]))\n",
        "rolling_cvar.plot(title='Rolling CVaR (20-day)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('CVaR')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print performance metrics\n",
        "for metric, value in metrics.items():\n",
        "    if metric in ['Max Drawdown', 'Annualized Return', 'Volatility', 'CVaR']:\n",
        "        print(f\"{metric}: {value:.2%}\")\n",
        "    else:\n",
        "        print(f\"{metric}: {value:.2f}\")\n",
        "# CELL 7 END"
      ],
      "metadata": {
        "id": "B3Np-_4-MX3e"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}